{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 144s 3s/step - loss: 3.7113 - accuracy: 0.5239 - val_loss: 0.6878 - val_accuracy: 0.5599\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 141s 3s/step - loss: 0.6669 - accuracy: 0.6391 - val_loss: 0.6836 - val_accuracy: 0.5501\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 130s 3s/step - loss: 0.5856 - accuracy: 0.7433 - val_loss: 0.6803 - val_accuracy: 0.5746\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 131s 3s/step - loss: 0.3264 - accuracy: 0.8664 - val_loss: 0.7772 - val_accuracy: 0.5892\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 131s 3s/step - loss: 0.1117 - accuracy: 0.9755 - val_loss: 1.1424 - val_accuracy: 0.5721\n",
      "13/13 [==============================] - 5s 403ms/step - loss: 1.1424 - accuracy: 0.5721\n",
      "Test Loss: 1.1423999071121216\n",
      "Test Accuracy: 0.5721271634101868\n"
     ]
    }
   ],
   "source": [
    "# Function to load and normalize an image\n",
    "def load_and_normalize_image(file_path):\n",
    "    image = Image.open(file_path)\n",
    "    image_array = np.array(image)\n",
    "    image_array = image_array / 255.0  # Normalize to [0, 1]\n",
    "    return image_array\n",
    "\n",
    "# Load the CSV file from your local directory\n",
    "csv_file_path = 'C:\\\\Users\\\\jbane\\\\Documents\\\\cda_fall2023_project\\\\data\\\\output\\\\combined_data_mtx.csv'  # Replace with your actual path to the CSV file\n",
    "combined_data_mtx = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Correct the file paths in the dataframe, assuming the 'file_path' column contains paths like 'data\\\\real_and_fake_face\\\\...'\n",
    "combined_data_mtx['file_path'] = combined_data_mtx['file_path'].str.replace(r'data\\\\', '', regex=True)\n",
    "\n",
    "# Base directory for images\n",
    "base_dir = 'C:\\\\Users\\\\jbane\\\\Documents\\\\cda_fall2023_project\\\\data\\\\'  # Replace with your actual base directory\n",
    "\n",
    "# Load and normalize images using the corrected paths\n",
    "combined_data_mtx['img_array'] = combined_data_mtx['file_path'].apply(\n",
    "    lambda x: load_and_normalize_image(os.path.join(base_dir, x.replace('\\\\', os.sep))))\n",
    "\n",
    "# Prepare labels\n",
    "y = combined_data_mtx['label'].apply(lambda x: 1 if x == 'real' else 0).values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = np.array(combined_data_mtx['img_array'].tolist())  # Convert list of arrays to a numpy array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model Architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1:])),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted CNN Model Architecture with Dropout and Regularization\n",
    "model2 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1:])),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "# Compile the model with a potentially smaller learning rate\n",
    "model2.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Early Stopping\n",
    "history = model2.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
