{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"gilettesent4.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbasol Once Showed Gillette How To Make a Co...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoycottGillette</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeetBarbasol arbasol Once Showed Gillette How ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BoycottGillette MeetBarbasol destinyisbright C...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MeetBarbasol MeetBarbasol Barbasol Once Showed...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets     Label\n",
       "0  Barbasol Once Showed Gillette How To Make a Co...  Negative\n",
       "1                                    BoycottGillette  Negative\n",
       "2  MeetBarbasol arbasol Once Showed Gillette How ...  Negative\n",
       "3  BoycottGillette MeetBarbasol destinyisbright C...  Negative\n",
       "4  MeetBarbasol MeetBarbasol Barbasol Once Showed...  Negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tweet = []\n",
    "Labels = []\n",
    "\n",
    "for row in df1[\"Tweets\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\",\"'re\" ,\"'m\"]\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Tweet.append(lemma_list)\n",
    "\n",
    "    for row in df1[\"Label\"]:\n",
    "        Labels.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = zip(Tweet, Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final_Data = []\n",
    "for r, v in combined:\n",
    "    bag_of_words(r)\n",
    "    Final_Data.append((bag_of_words(r),v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(Final_Data)\n",
    "print(len(Final_Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance with Unigrams \n",
      "Accuracy: 0.6883116883116883\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = Final_Data[0:188], Final_Data[188:]\n",
    "\n",
    "import nltk\n",
    "import collections\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure) \n",
    "from nltk import metrics\n",
    "\n",
    "refsets = collections. defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "print(\"Naive Bayes Performance with Unigrams \")    \n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramNB Results\n",
      "Brand Positive Precision: 0.6\n",
      "Brand Positive Recall: 0.75\n",
      "Brand Positive F-measure: 0.6666666666666666\n",
      "Brand Damaging Precision: 0.7837837837837838\n",
      "Brand Damaging Recall: 0.7837837837837838\n",
      "Brand Damaging F-measure: 0.7073170731707318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "nbrefset = collections.defaultdict(set)\n",
    "nbtestset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    nbrefset[label].add(i)\n",
    "    observed = nb_classifier.classify(feats)\n",
    "    nbtestset[observed].add(i)\n",
    "    \n",
    "print(\"UnigramNB Results\")\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(nbtestset['Negative'], nbrefset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    love = True           Positi : Negati =      5.8 : 1.0\n",
      "               'gillette = True           Positi : Negati =      4.0 : 1.0\n",
      "                    away = True           Positi : Negati =      4.0 : 1.0\n",
      "              boycotting = True           Positi : Negati =      4.0 : 1.0\n",
      "                    look = True           Positi : Negati =      4.0 : 1.0\n",
      "                     guy = True           Positi : Negati =      4.0 : 1.0\n",
      "                   video = True           Positi : Negati =      4.0 : 1.0\n",
      "                    real = True           Negati : Positi =      3.7 : 1.0\n",
      "                     get = True           Negati : Positi =      3.5 : 1.0\n",
      "                      ad = True           Positi : Negati =      3.2 : 1.0\n",
      "                    hear = True           Positi : Negati =      3.1 : 1.0\n",
      "                   every = True           Positi : Negati =      3.1 : 1.0\n",
      "                     son = True           Positi : Negati =      3.1 : 1.0\n",
      "                    many = True           Positi : Negati =      3.1 : 1.0\n",
      "                    show = True           Positi : Negati =      3.1 : 1.0\n",
      "                     day = True           Positi : Negati =      3.1 : 1.0\n",
      "                    dick = True           Positi : Negati =      3.1 : 1.0\n",
      "                   truly = True           Positi : Negati =      3.1 : 1.0\n",
      "                   'this = True           Positi : Negati =      3.1 : 1.0\n",
      "                  please = True           Positi : Negati =      3.1 : 1.0\n",
      "                     fit = True           Positi : Negati =      3.1 : 1.0\n",
      "                    take = True           Positi : Negati =      3.0 : 1.0\n",
      "                  people = True           Positi : Negati =      2.9 : 1.0\n",
      "             masculinity = True           Positi : Negati =      2.8 : 1.0\n",
      "                   still = True           Negati : Positi =      2.7 : 1.0\n",
      "                     boy = True           Positi : Negati =      2.4 : 1.0\n",
      "              gillettead = True           Negati : Positi =      2.4 : 1.0\n",
      "                      'i = True           Positi : Negati =      2.2 : 1.0\n",
      "                    iâm = True           Positi : Negati =      2.2 : 1.0\n",
      "                   aware = True           Positi : Negati =      2.2 : 1.0\n",
      "                 proving = True           Positi : Negati =      2.2 : 1.0\n",
      "                    good = True           Positi : Negati =      2.2 : 1.0\n",
      "               literally = True           Positi : Negati =      2.2 : 1.0\n",
      "                  happen = True           Positi : Negati =      2.2 : 1.0\n",
      "                    talk = True           Positi : Negati =      2.2 : 1.0\n",
      "                everyone = True           Positi : Negati =      2.2 : 1.0\n",
      "                  listen = True           Positi : Negati =      2.2 : 1.0\n",
      "                   itâs = True           Positi : Negati =      2.2 : 1.0\n",
      "                   great = True           Positi : Negati =      2.2 : 1.0\n",
      "                    open = True           Positi : Negati =      2.2 : 1.0\n",
      "                   iâve = True           Positi : Negati =      2.2 : 1.0\n",
      "                    know = True           Negati : Positi =      2.2 : 1.0\n",
      "                 someone = True           Negati : Positi =      2.2 : 1.0\n",
      "                   point = True           Negati : Positi =      2.2 : 1.0\n",
      "                 company = True           Negati : Positi =      2.2 : 1.0\n",
      "         gilletteboycott = True           Negati : Positi =      2.2 : 1.0\n",
      "              commercial = True           Positi : Negati =      2.1 : 1.0\n",
      "                  asking = True           Positi : Negati =      2.1 : 1.0\n",
      "                    male = True           Positi : Negati =      2.1 : 1.0\n",
      "                   brand = True           Positi : Negati =      1.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramDT Results\n",
      "Accuracy: 0.6883116883116883\n",
      "Brand Positive Precision: 0.6\n",
      "Brand Positive Recall: 0.75\n",
      "Brand Positive F-measure: 0.6666666666666666\n",
      "Brand Damaging Precision: 0.7837837837837838\n",
      "Brand Damaging Recall: 0.7837837837837838\n",
      "Brand Damaging F-measure: 0.7073170731707318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, \n",
    "                                             binary=True, \n",
    "                                             entropy_cutoff=0.8, \n",
    "                                             depth_cutoff=5, \n",
    "                                             support_cutoff=30)\n",
    "refset = collections.defaultdict(set)\n",
    "testset = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = dt_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "\n",
    "print(\"UnigramDT Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(nbtestset['Negative'], nbrefset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnigramsLogit Results\n",
      "Accuracy: 0.6883116883116883\n",
      "Brand Positive Precision: 0.6\n",
      "Brand Positive Recall: 0.75\n",
      "Brand Positive F-measure: 0.6666666666666666\n",
      "Brand Damaging Precision: 0.7837837837837838\n",
      "Brand Damaging Recall: 0.7837837837837838\n",
      "Brand Damaging F-measure: 0.7073170731707318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "logit_classifier = MaxentClassifier.train(train_set, algorithm='gis', trace=0, max_iter=10, min_lldelta=0.5)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refset[label].add(i)\n",
    "    observed = logit_classifier.classify(feats)\n",
    "    testset[observed].add(i)\n",
    "    \n",
    "print(\"UnigramsLogit Results\")\n",
    "print(\"Accuracy:\",nltk.classify.accuracy(classifier, test_set))\n",
    "print('Brand Positive Precision:', precision(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive Recall:', recall(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Positive F-measure:', f_measure(refsets['Positive'], testsets['Positive']))\n",
    "print('Brand Damaging Precision:', precision(refsets['Negative'], testsets['Negative']))\n",
    "print('Brand Damaging Recall:', recall(nbtestset['Negative'], nbrefset['Negative']))\n",
    "print('Brand Damaging F-measure:', f_measure(refsets['Negative'], testsets['Negative']))\n",
    "print(\"\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
